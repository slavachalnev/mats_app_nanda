{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/slava/safety/mats_app_nanda/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformer_lens\n",
    "from transformer_lens import HookedTransformer\n",
    "\n",
    "from IPython.display import display\n",
    "import circuitsvis as cv\n",
    "\n",
    "from model import SparseAutoencoder\n",
    "from config import SAEConfig\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu' # keep everything on cpu for now\n",
    "checkpoints_path = \"/Users/slava/fun/pos_sae/converted_checkpoints\" # TODO: move checkpoints to model hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model = HookedTransformer.from_pretrained('gpt2-small', device=device)\n",
    "\n",
    "# Load the SAEs\n",
    "saes = [] # one for each layer\n",
    "for layer in range(model.cfg.n_layers):\n",
    "    path = f\"{checkpoints_path}/final_sparse_autoencoder_gpt2-small_blocks.{layer}.hook_resid_pre_24576\"\n",
    "    sae = SparseAutoencoder.load_from_pretrained(path, silent=True)\n",
    "    saes.append(sae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### For use with activation patching ###\n",
    "# text = \"the team traveled by\" # bus\n",
    "# text = \"the team succeeded by\" # working together\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"They raised awareness for the cause by\"\n",
    "\n",
    "tokens = model.tokenizer.encode(text, return_tensors=\"pt\")\n",
    "tokens = torch.cat([torch.tensor([[model.tokenizer.bos_token_id]]), tokens], dim=1) # prepend bos\n",
    "\n",
    "logits, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resid in shape torch.Size([8, 768])\n",
      "feature_acts shape torch.Size([8, 24576])\n",
      "tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 70.1081],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "target_feature_layer = 11\n",
    "target_feature_id = 23531\n",
    "\n",
    "# get feature activations\n",
    "target_f_sae = saes[target_feature_layer]\n",
    "\n",
    "resid_in = cache[\"resid_post\", target_feature_layer][0]\n",
    "print('resid in shape', resid_in.shape)\n",
    "\n",
    "_, feature_acts, _, _, _ = target_f_sae(resid_in)\n",
    "print('feature_acts shape', feature_acts.shape)\n",
    "\n",
    "target_f_acts = feature_acts[:, target_feature_id]\n",
    "print(target_f_acts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(cv.attention.attention_patterns(\n",
    "#     tokens=model.to_str_tokens(tokens),\n",
    "#     attention=cache['pattern', 11][0],\n",
    "#     attention_head_names=[f\"L0H{i}\" for i in range(12)],\n",
    "# ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(cv.attention.attention_patterns(\n",
    "#     tokens=model.to_str_tokens(tokens),\n",
    "#     attention=cache['pattern', 10][0],\n",
    "#     attention_head_names=[f\"L0H{i}\" for i in range(12)],\n",
    "# ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
